{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3bkj5QQDeCKbeBEE5Z+iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JithinBV/Docbot/blob/main/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE-k2xn4r1v4",
        "outputId": "465085b9-d175-4ed5-d227-64cd30d751ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "torch\n",
        "accelerate\n",
        "sentence_transformers\n",
        "streamlit_chat\n",
        "streamlit\n",
        "chromadb\n",
        "tiktoken\n",
        "ctransformers\n",
        "huggingface_hub\n",
        "pypdf\n",
        "python-dotenv\n",
        "replicate\n",
        "docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from streamlit_chat import message\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.llms import Replicate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import tempfile\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def initialise_session_state():\n",
        "  if \"history\" not in st.session_state:\n",
        "    st.session_state['history'] = []\n",
        "  if \"generated\" not in st.session_state:\n",
        "    st.session_state['generated'] = [\"hello! Ask me anything\"]\n",
        "  if \"past\" not in st.session_state:\n",
        "    st.session_state['past'] = ['Hey!']\n",
        "\n",
        "def conversation_chat(query,chain,history):\n",
        "  result = chain({\"question\":query,\"chat_history\":history})\n",
        "  history.append((query,result['answer']))\n",
        "  return result['answer']\n",
        "\n",
        "def display_chat_history(chain):\n",
        "  reply_container = st.container()\n",
        "  container = st.container()\n",
        "\n",
        "  with container:\n",
        "    with st.form(key=\"my_form\",clear_on_submit=True):\n",
        "      user_input = st.text_input(\"Question:\",placeholder=\"Ask about your Documents\",key = \"input\")\n",
        "      submit_button = st.form_submit_button(label=\"send\")\n",
        "    if submit_button and user_input:\n",
        "      with st.spinner(\"Generating response.....\"):\n",
        "        output = conversation_chat(user_input,chain,st.session_state['history'])\n",
        "        st.session_state['past'].append(user_input)\n",
        "        st.session_state['generated'].append(output)\n",
        "  if st.session_state['generated']:\n",
        "    with reply_container:\n",
        "      for i in range(len(st.session_state['generated'])):\n",
        "        message(st.session_state['past'][i],is_user=True,key=str(i) + \"_user\",avatar_style=\"thumbs\")\n",
        "        message(st.session_state['generated'][i],key=str(i) ,avatar_style=\"fun-emoji\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_conversational_chain(vectordb):\n",
        "  load_dotenv()\n",
        "  llm = Replicate(\n",
        "      streaming = True,\n",
        "      model = \"meta/llama-2-7b-chat:8e6975e5ed6174911a6ff3d60540dfd4844201974602551e10e9e87ab143d81e\",\n",
        "      callbacks = [StreamingStdOutCallbackHandler],\n",
        "      input = {\"temparature\":0.01,\"max_length\":500,\"top_1\":1}\n",
        "  )\n",
        "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "  chain = ConversationalRetrievalChain.from_llm(llm=llm,chain_type=\"stuff\",\n",
        "                                                retriever=vectordb.as_retriever(search_kwargs={\"k\":2}),\n",
        "                                                memory=memory)\n",
        "\n",
        "  return chain\n",
        "\n",
        "\n",
        "def main():\n",
        "  initialise_session_state()\n",
        "\n",
        "  st.title(\"Multi-Docs Chatbot\")\n",
        "  st.sidebar.title(\"Document processing\")\n",
        "  uploaded_files = st.sidebar.file_uploader(\"uploaded files\",accept_multiple_files=True)\n",
        "\n",
        "  if uploaded_files:\n",
        "    text = []\n",
        "    for file in uploaded_files:\n",
        "      file_extension = os.path.splitext(file.name)[1]\n",
        "      with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "        temp_file.write(file.read())\n",
        "        temp_file_path = temp_file.name\n",
        "    loader = None\n",
        "    if file_extension == \".pdf\":\n",
        "      loader = PyPDFLoader(temp_file_path)\n",
        "    elif file_extension == \".docx\" or file_extension == \".doc\":\n",
        "      loader = Docx2txtLoader(temp_file_path)\n",
        "    elif file_extension == \".txt\":\n",
        "      loader = TextLoader(temp_file_path)\n",
        "    if loader:\n",
        "      text.extend(loader.load())\n",
        "      os.remove(temp_file_path)\n",
        "      text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=500, chunk_overlap=100,length_function=len)\n",
        "      text_chunks = text_splitter.split_documents(text)\n",
        "\n",
        "      embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                     model_kwargs={'device':\"cpu\"})\n",
        "\n",
        "      vectordb=Chroma.from_documents(text_chunks,embedding=embeddings)\n",
        "\n",
        "      chain = create_conversational_chain(vectordb)\n",
        "\n",
        "      display_chat_history(chain)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRwpQqk3sRTk",
        "outputId": "4d0c2af8-2d9c-467c-fa34-c64d3f34c41a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "REPLICATE_API_TOKEN = r8_99kfCw9YCFnk4etLwZV1V3Fcu4Q2mAA2TS0Sr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwzwDuurAmuU",
        "outputId": "787dcc3c-de66-4360-a471-57a0349ea358"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Jdn_2S-aqbY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9-xzIyp_fw7",
        "outputId": "46517579-2c2f-405d-e64c-edb73be27d51"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmuqDkU9A0rC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJFovoIACpeJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}